{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc378879",
   "metadata": {},
   "source": [
    "# Class Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1c117",
   "metadata": {},
   "source": [
    "## In class activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b9c178",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib.pyplot import subplots\n",
    "#import statsmodels.api as sm\n",
    "from plotnine import *\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as sm\n",
    "#import ISLP as islp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8f84d",
   "metadata": {},
   "source": [
    "### Ames Housing data\n",
    "\n",
    "\n",
    "Please take a look at the Ames Hoursing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7792c845",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw=pd.read_csv(\"ames_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde9d19",
   "metadata": {},
   "source": [
    "Use data of `ames_raw` up to 2008 predict the housing price for the later years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb9eca2",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw_2009, ames_raw_2008= ames_raw.query('`Yr Sold`>=2008').copy(), ames_raw.query('`Yr Sold` <2008').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89dccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1319 entries, 1611 to 2929\n",
      "Data columns (total 82 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order            1319 non-null   int64  \n",
      " 1   PID              1319 non-null   int64  \n",
      " 2   MS SubClass      1319 non-null   int64  \n",
      " 3   MS Zoning        1319 non-null   object \n",
      " 4   Lot Frontage     1106 non-null   float64\n",
      " 5   Lot Area         1319 non-null   int64  \n",
      " 6   Street           1319 non-null   object \n",
      " 7   Alley            84 non-null     object \n",
      " 8   Lot Shape        1319 non-null   object \n",
      " 9   Land Contour     1319 non-null   object \n",
      " 10  Utilities        1319 non-null   object \n",
      " 11  Lot Config       1319 non-null   object \n",
      " 12  Land Slope       1319 non-null   object \n",
      " 13  Neighborhood     1319 non-null   object \n",
      " 14  Condition 1      1319 non-null   object \n",
      " 15  Condition 2      1319 non-null   object \n",
      " 16  Bldg Type        1319 non-null   object \n",
      " 17  House Style      1319 non-null   object \n",
      " 18  Overall Qual     1319 non-null   int64  \n",
      " 19  Overall Cond     1319 non-null   int64  \n",
      " 20  Year Built       1319 non-null   int64  \n",
      " 21  Year Remod/Add   1319 non-null   int64  \n",
      " 22  Roof Style       1319 non-null   object \n",
      " 23  Roof Matl        1319 non-null   object \n",
      " 24  Exterior 1st     1319 non-null   object \n",
      " 25  Exterior 2nd     1319 non-null   object \n",
      " 26  Mas Vnr Type     524 non-null    object \n",
      " 27  Mas Vnr Area     1307 non-null   float64\n",
      " 28  Exter Qual       1319 non-null   object \n",
      " 29  Exter Cond       1319 non-null   object \n",
      " 30  Foundation       1319 non-null   object \n",
      " 31  Bsmt Qual        1286 non-null   object \n",
      " 32  Bsmt Cond        1286 non-null   object \n",
      " 33  Bsmt Exposure    1284 non-null   object \n",
      " 34  BsmtFin Type 1   1286 non-null   object \n",
      " 35  BsmtFin SF 1     1319 non-null   float64\n",
      " 36  BsmtFin Type 2   1286 non-null   object \n",
      " 37  BsmtFin SF 2     1319 non-null   float64\n",
      " 38  Bsmt Unf SF      1319 non-null   float64\n",
      " 39  Total Bsmt SF    1319 non-null   float64\n",
      " 40  Heating          1319 non-null   object \n",
      " 41  Heating QC       1319 non-null   object \n",
      " 42  Central Air      1319 non-null   object \n",
      " 43  Electrical       1319 non-null   object \n",
      " 44  1st Flr SF       1319 non-null   int64  \n",
      " 45  2nd Flr SF       1319 non-null   int64  \n",
      " 46  Low Qual Fin SF  1319 non-null   int64  \n",
      " 47  Gr Liv Area      1319 non-null   int64  \n",
      " 48  Bsmt Full Bath   1319 non-null   float64\n",
      " 49  Bsmt Half Bath   1319 non-null   float64\n",
      " 50  Full Bath        1319 non-null   int64  \n",
      " 51  Half Bath        1319 non-null   int64  \n",
      " 52  Bedroom AbvGr    1319 non-null   int64  \n",
      " 53  Kitchen AbvGr    1319 non-null   int64  \n",
      " 54  Kitchen Qual     1319 non-null   object \n",
      " 55  TotRms AbvGrd    1319 non-null   int64  \n",
      " 56  Functional       1319 non-null   object \n",
      " 57  Fireplaces       1319 non-null   int64  \n",
      " 58  Fireplace Qu     697 non-null    object \n",
      " 59  Garage Type      1255 non-null   object \n",
      " 60  Garage Yr Blt    1254 non-null   float64\n",
      " 61  Garage Finish    1254 non-null   object \n",
      " 62  Garage Cars      1318 non-null   float64\n",
      " 63  Garage Area      1318 non-null   float64\n",
      " 64  Garage Qual      1254 non-null   object \n",
      " 65  Garage Cond      1254 non-null   object \n",
      " 66  Paved Drive      1319 non-null   object \n",
      " 67  Wood Deck SF     1319 non-null   int64  \n",
      " 68  Open Porch SF    1319 non-null   int64  \n",
      " 69  Enclosed Porch   1319 non-null   int64  \n",
      " 70  3Ssn Porch       1319 non-null   int64  \n",
      " 71  Screen Porch     1319 non-null   int64  \n",
      " 72  Pool Area        1319 non-null   int64  \n",
      " 73  Pool QC          10 non-null     object \n",
      " 74  Fence            249 non-null    object \n",
      " 75  Misc Feature     39 non-null     object \n",
      " 76  Misc Val         1319 non-null   int64  \n",
      " 77  Mo Sold          1319 non-null   int64  \n",
      " 78  Yr Sold          1319 non-null   int64  \n",
      " 79  Sale Type        1319 non-null   object \n",
      " 80  Sale Condition   1319 non-null   object \n",
      " 81  SalePrice        1319 non-null   int64  \n",
      "dtypes: float64(11), int64(28), object(43)\n",
      "memory usage: 855.3+ KB\n"
     ]
    }
   ],
   "source": [
    "ames_raw_2008.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da715eb",
   "metadata": {},
   "source": [
    "Use the following loss function calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145b46d4",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_loss(prediction,actual):\n",
    "  difpred = actual-prediction\n",
    "  RMSE =pow(difpred.pow(2).mean(),1/2)\n",
    "  operation_loss=abs(sum(difpred[difpred<0]))+sum(0.1*actual[difpred>0])\n",
    "  return RMSE,operation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124297b",
   "metadata": {},
   "source": [
    "Use a simple neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1cd4b1f",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE,echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.952707052230835\n",
      "Epoch: 20, Loss: 0.8708751797676086\n",
      "Epoch: 30, Loss: 0.7827321290969849\n",
      "Epoch: 40, Loss: 0.6860052347183228\n",
      "Epoch: 50, Loss: 0.5846449136734009\n",
      "Epoch: 60, Loss: 0.48753291368484497\n",
      "Epoch: 70, Loss: 0.40397322177886963\n",
      "Epoch: 80, Loss: 0.33894506096839905\n",
      "Epoch: 90, Loss: 0.29235079884529114\n",
      "Epoch: 100, Loss: 0.26089081168174744\n"
     ]
    }
   ],
   "source": [
    "# Define your neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define target column\n",
    "inputs = ames_raw_2008[['Lot Area', 'Overall Qual', 'Overall Cond', 'Year Built', \n",
    "                        'Year Remod/Add', '1st Flr SF', '2nd Flr SF', 'Gr Liv Area',\n",
    "                        'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr',\n",
    "                        'TotRms AbvGrd', 'Pool Area', 'Mo Sold', 'Yr Sold']]\n",
    "targets = ames_raw_2008['SalePrice']\n",
    "\n",
    "# Standardize inputs and targets\n",
    "input_scaler = StandardScaler()\n",
    "inputs = input_scaler.fit_transform(inputs)\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "targets = target_scaler.fit_transform(targets.values.reshape(-1, 1))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "# Create an instance of your neural network\n",
    "nnfit_2008 = NeuralNetwork()\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(nnfit_2008.parameters(), lr=0.01)\n",
    "\n",
    "# Perform training\n",
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    outputs = nnfit_2008(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90018571",
   "metadata": {},
   "source": [
    "When you decide on your model use the following to come up with your test loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043ba85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43129.36117382642, 46816852.18125)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the same input columns\n",
    "inputs_2009 = ames_raw_2009[['Lot Area', 'Overall Qual', 'Overall Cond', 'Year Built', \n",
    "                             'Year Remod/Add', '1st Flr SF', '2nd Flr SF', 'Gr Liv Area',\n",
    "                             'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr',\n",
    "                             'TotRms AbvGrd', 'Pool Area', 'Mo Sold', 'Yr Sold']]\n",
    "\n",
    "# Standardize the inputs using the same scaler\n",
    "inputs_2009 = input_scaler.transform(inputs_2009)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "inputs_2009 = torch.tensor(inputs_2009, dtype=torch.float32)\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "outputs_2009 = nnfit_2008(inputs_2009)\n",
    "\n",
    "# Convert the predictions back to the original scale\n",
    "pred_2009 = target_scaler.inverse_transform(outputs_2009.detach().numpy())\n",
    "\n",
    "# Convert pred_2009 to a one-dimensional array\n",
    "pred_2009 = pred_2009.ravel()\n",
    "\n",
    "# Predict using ames_raw_2009\n",
    "calc_loss(pred_2009,ames_raw_2009.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45d1e7",
   "metadata": {},
   "source": [
    "Try to answer the following additional questions.\n",
    "\n",
    "- Does your model indicate a good fit?\n",
    "\n",
    "\n",
    "- How does your model result compare to the previous models you fit?\n",
    "\n",
    "\n",
    "- Can you explain what feature was important determinant of the price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf9dd0",
   "metadata": {},
   "source": [
    "### COVID 19 Survival in Mexico\n",
    "\n",
    "Let's revisit COVID-19 in Mexico dataset from the [Mexican government](https://datos.gob.mx/busca/dataset/informacion-referente-a-casos-covid-19-en-mexico).  This data is a version downloaded from [Kaggle](https://www.kaggle.com/datasets/meirnizri/covid19-dataset?resource=download).  The raw dataset consists of 21 unique features and 1,048,576 unique patients. In the Boolean features, 1 means \"yes\" and 2 means \"no\". values as 97 and 99 are missing data.\n",
    "\n",
    "- sex: 1 for female and 2 for male.\n",
    "- age: of the patient.\n",
    "- classification: COVID test findings. Values 1-3 mean that the patient was diagnosed with COVID in different degrees. 4 or higher means that the patient is not a carrier of COVID or that the test is inconclusive.\n",
    "- patient type: type of care the patient received in the unit. 1 for returned home and 2 for hospitalization.\n",
    "- pneumonia: whether the patient already have air sacs inflammation or not.\n",
    "- pregnancy: whether the patient is pregnant or not.\n",
    "- diabetes: whether the patient has diabetes or not.\n",
    "- copd: Indicates whether the patient has Chronic obstructive pulmonary disease or not.\n",
    "- asthma: whether the patient has asthma or not.\n",
    "- inmsupr: whether the patient is immunosuppressed or not.\n",
    "- hypertension: whether the patient has hypertension or not.\n",
    "- cardiovascular: whether the patient has heart or blood vessels related disease.\n",
    "- renal chronic: whether the patient has chronic renal disease or not.\n",
    "- other disease: whether the patient has other disease or not.\n",
    "- obesity: whether the patient is obese or not.\n",
    "- tobacco: whether the patient is a tobacco user.\n",
    "- usmr: Indicates whether the patient treated medical units of the first, second or third level.\n",
    "- medical unit: type of institution of the National Health System that provided the care.\n",
    "- intubed: whether the patient was connected to the ventilator.\n",
    "- icu: Indicates whether the patient had been admitted to an Intensive Care Unit.\n",
    "- date died: If the patient died indicate the date of death, and 9999-99-99 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef41dc",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "Train_COVID= pd.read_csv('Train_COVID.zip',compression='zip')\n",
    "Test_COVID= pd.read_csv('Test_COVID.zip',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9846d1",
   "metadata": {},
   "source": [
    "- Fit a sequence model that predicts the number of cases a week a head.\n",
    "\n",
    "- Modify your model to make prediction for different gender.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2ddbc",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63065e78",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db356786",
   "metadata": {},
   "source": [
    "## Problem set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2c5a9",
   "metadata": {},
   "source": [
    "### Writing your own gradient decent\n",
    "\n",
    "Consider the simple function $R(\\beta) = sin(\\beta) + \\beta/10$.\n",
    "\n",
    "(a) Draw a graph of this function over the range $\\beta \\in [−6, 6]$.\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683d706",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788e2b3",
   "metadata": {},
   "source": [
    "(b) What is the derivative of this function?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6932c",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c379",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(c) Given $\\beta_0 = 2.3$, run gradient descent to find a local minimum of $R(\\beat)$ using a learning rate of $\\rho= 0.1$. Show each of $\\beta_0,\\beta_1,\\dots$ in your plot, as well as the final answer.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9f93f",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134f645",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(d) Repeat with $\\beta_0 = 1.4$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efea5a0",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b33b24",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73f6ae",
   "metadata": {},
   "source": [
    "### Default\n",
    "\n",
    "Fit a neural network to the Default data. Use a single hidden layer with 10 units, and dropout regularization. Have a look at Labs 10.9.1–10.9.2 for guidance. Compare the classification performance of your model with that of linear logistic regression.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15d9d3",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb5727",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d06410",
   "metadata": {},
   "source": [
    "### IMDb\n",
    "\n",
    "Repeat the analysis of Lab 10.9.5 on the IMDb data using a similarly structured neural network. We used 16 hidden units at each of two hidden layers. Explore the effect of increasing this to 32 and 64 units per layer, with and without 30% dropout regularization.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d63690",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b61f2",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e719c",
   "metadata": {},
   "source": [
    "### NYSE\n",
    "\n",
    "Fit a lag-5 autoregressive model to the NYSE data, as described in the text and Lab 10.9.6. Refit the model with a 12-level factor representing the month. Does this factor improve the performance of the model?\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537a6d2",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82790743",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79190c",
   "metadata": {},
   "source": [
    "### NYSE 2\n",
    "In Section 10.9.6, we showed how to fit a linear AR model to the\n",
    "NYSE data using the `LinearRegression()` function. However, we also\n",
    "mentioned that we can “flatten” the short sequences produced for\n",
    "the RNN model in order to fit a linear AR model. Use this latter\n",
    "approach to fit a linear AR model to the NYSE data. Compare the test\n",
    "R2 of this linear AR model to that of the linear AR model that we fit\n",
    "in the lab. What are the advantages/disadvantages of each approach?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b49f2e",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6f42d",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "Repeat the previous exercise, but now fit a nonlinear AR model by\n",
    "“flattening” the short sequences produced for the RNN model.\n",
    "\n",
    " Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0a120",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5e731",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018aaf64",
   "metadata": {},
   "source": [
    "### NYSE 3\n",
    "\n",
    "Consider the RNN fit to the NYSE data in Section 10.9.6. Modify the code to allow inclusion of the variable day_of_week, and fit the RNN. Compute the test $R^2$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d3d82",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce0591",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d647a4b",
   "metadata": {},
   "source": [
    "### CNN on photo\n",
    "\n",
    "From your collection of personal photographs, pick 10 images of animals\n",
    "(such as dogs, cats, birds, farm animals, etc.). If the subject\n",
    "does not occupy a reasonable part of the image, then crop the image.\n",
    "Now use a pretrained image classification CNN as in Lab 10.9.4 to\n",
    "predict the class of each of your images, and report the probabilities\n",
    "for the top five predicted classes for each image.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c81612",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "from torchvision.models import alexnet\n",
    "from torchvision.models import AlexNet_Weights\n",
    " \n",
    "weights=AlexNet_Weights.IMAGENET1K_V1\n",
    "alexnet_model= alexnet(weights=weights)\n",
    "print(alexnet_model)\n",
    " \n",
    "# You can also do the same by down laoding from torch.hub\n",
    "# AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    " \n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([            #[1]\n",
    "transforms.Resize(256),                   #[2]\n",
    "transforms.CenterCrop(224),               #[3]\n",
    "transforms.ToTensor(),                    #[4]\n",
    "transforms.Normalize(                      #[5]\n",
    "mean=[0.485, 0.456, 0.406],               #[6]\n",
    "std=[0.229, 0.224, 0.225]                  #[7]\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be231e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: IMG_7592.JPG, Category: spindle, Score: 11.6%\n",
      "File: IMG_7976.JPG, Category: tiger cat, Score: 17.2%\n",
      "File: IMG_8170.JPG, Category: lion, Score: 39.3%\n",
      "File: IMG_9454.JPG, Category: tabby, Score: 35.2%\n",
      "File: IMG_3752.JPG, Category: Persian cat, Score: 36.1%\n",
      "File: IMG_5013_polarr.jpg, Category: bathtub, Score: 14.1%\n",
      "File: IMG_9458.JPG, Category: Siamese cat, Score: 8.0%\n",
      "File: IMG_4641_polarr.JPG, Category: Siamese cat, Score: 88.8%\n",
      "File: IMG_6126.JPG, Category: Persian cat, Score: 26.6%\n",
      "File: IMG_8877.JPG, Category: Cardigan, Score: 17.1%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "currentdir=os.getcwd()\n",
    "os.chdir('images')\n",
    "files=os.listdir(\".\")\n",
    " \n",
    "# Import Pillow\n",
    "from PIL import Image\n",
    "\n",
    "image_extensions = ['.jpg', '.png', '.jpeg', '.bmp', '.gif']\n",
    "\n",
    "for file in files:\n",
    "  if os.path.splitext(file)[1].lower() in image_extensions:\n",
    "    img = Image.open(file)\n",
    "\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "    alexnet_model.eval()\n",
    "\n",
    "    out = alexnet_model(batch_t).squeeze(0).softmax(0)\n",
    "    class_id = out.argmax().item()\n",
    "    score = out[class_id].item()\n",
    "    category_name = weights.meta[\"categories\"][class_id]\n",
    "    print(f\"File: {file}, Category: {category_name}, Score: {100 * score:.1f}%\")\n",
    " \n",
    "os.chdir(currentdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d56a27",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "Rmd_chunk_options": {
   "author": "Your Name",
   "date": "2022-12-21",
   "output": "github_document",
   "title": "Deep Learning"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "",
     ""
    ],
    [
     "css",
     "css",
     "",
     ""
    ],
    [
     "Python3",
     "ir",
     "",
     ""
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
